
R version 3.2.3 (2015-12-10) -- "Wooden Christmas-Tree"
Copyright (C) 2015 The R Foundation for Statistical Computing
Platform: x86_64-apple-darwin13.4.0 (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

[Previously saved workspace restored]

> ## 7. Estimation of survival probabilities using capture-recapture data
> ## 7.9. Parameter identifiability
> 
> library(rstan)
Loading required package: ggplot2
rstan (Version 2.8.1, packaged: 2015-11-18 17:18:35 UTC, GitRev: 05c3d0058b6a)
For execution on a local, multicore CPU with excess RAM we recommend calling
rstan_options(auto_write = TRUE)
options(mc.cores = parallel::detectCores())
> rstan_options(auto_write = TRUE)
> options(mc.cores = parallel::detectCores())
> set.seed(123)
> 
> ## Read data
> ## The data generation code is in bpa-code.txt, available at
> ## http://www.vogelwarte.ch/de/projekte/publikationen/bpa/complete-code-and-data-files-of-the-book.html
> stan_data <- read_rdump("cjs_t_t.data.R")
> 
> ## Parameters monitored
> params <- c("phi_t", "p_t")
> 
> ## MCMC settings
> ni <- 2000
> nt <- 1
> nb <- 1000
> nc <- 4
> 
> ## Initial values
> inits <- lapply(1:nc, function(i) {
+     list(phi_t = runif((dim(stan_data$y)[2] - 1), 0, 1),
+          p_t = runif((dim(stan_data$y)[2] - 1), 0, 1))})
> 
> ## Call Stan from R
> cjs_t_t  <- stan("cjs_t_t.stan",
+                  data = stan_data, init = inits, pars = params,
+                  chains = nc, iter = ni, warmup = nb, thin = nt,
+                  seed = 1,
+                  open_progress = FALSE)
starting worker pid=9597 on localhost:11325 at 23:20:31.913
starting worker pid=9605 on localhost:11325 at 23:20:32.046
starting worker pid=9613 on localhost:11325 at 23:20:32.181
starting worker pid=9621 on localhost:11325 at 23:20:32.321

SAMPLING FOR MODEL 'cjs_t_t' NOW (CHAIN 1).

Chain 1, Iteration:    1 / 2000 [  0%]  (Warmup)
SAMPLING FOR MODEL 'cjs_t_t' NOW (CHAIN 2).

Chain 2, Iteration:    1 / 2000 [  0%]  (Warmup)
SAMPLING FOR MODEL 'cjs_t_t' NOW (CHAIN 3).

Chain 3, Iteration:    1 / 2000 [  0%]  (Warmup)
SAMPLING FOR MODEL 'cjs_t_t' NOW (CHAIN 4).

Chain 4, Iteration:    1 / 2000 [  0%]  (Warmup)
Chain 1, Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 2, Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 3, Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 4, Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 1, Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 3, Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 2, Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 4, Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 1, Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 2, Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 3, Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 1, Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 4, Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 2, Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 3, Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 1, Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 1, Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 4, Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 2, Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 2, Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 3, Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 3, Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 1, Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 4, Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 4, Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 2, Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 3, Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 1, Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 2, Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 4, Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 1, Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 3, Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 2, Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 4, Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 1, Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 2, Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 3, Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 4, Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 2, Iteration: 2000 / 2000 [100%]  (Sampling)
#  Elapsed Time: 9.51073 seconds (Warm-up)
#                8.31113 seconds (Sampling)
#                17.8219 seconds (Total)


Chain 1, Iteration: 2000 / 2000 [100%]  (Sampling)
#  Elapsed Time: 9.28892 seconds (Warm-up)
#                9.1268 seconds (Sampling)
#                18.4157 seconds (Total)


Chain 4, Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 3, Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 4, Iteration: 2000 / 2000 [100%]  (Sampling)
#  Elapsed Time: 10.0076 seconds (Warm-up)
#                9.41617 seconds (Sampling)
#                19.4238 seconds (Total)


Chain 3, Iteration: 2000 / 2000 [100%]  (Sampling)
#  Elapsed Time: 9.22033 seconds (Warm-up)
#                11.247 seconds (Sampling)
#                20.4673 seconds (Total)

> 
> ## Summarize posteriors
> print(cjs_t_t, digits = 3)
Inference for Stan model: cjs_t_t.
4 chains, each with iter=2000; warmup=1000; thin=1; 
post-warmup draws per chain=1000, total post-warmup draws=4000.

              mean se_mean    sd     2.5%      25%      50%      75%    97.5%
phi_t[1]     0.812   0.002 0.130    0.527    0.726    0.831    0.920    0.992
phi_t[2]     0.581   0.003 0.135    0.352    0.485    0.564    0.664    0.886
phi_t[3]     0.536   0.003 0.144    0.294    0.432    0.517    0.623    0.864
phi_t[4]     0.490   0.002 0.118    0.289    0.405    0.479    0.561    0.753
phi_t[5]     0.560   0.003 0.122    0.352    0.475    0.546    0.632    0.841
phi_t[6]     0.395   0.002 0.090    0.237    0.331    0.387    0.452    0.585
phi_t[7]     0.764   0.002 0.122    0.518    0.677    0.766    0.855    0.978
phi_t[8]     0.395   0.002 0.097    0.233    0.326    0.384    0.453    0.615
phi_t[9]     0.729   0.003 0.122    0.500    0.643    0.727    0.818    0.961
phi_t[10]    0.510   0.003 0.130    0.307    0.417    0.490    0.584    0.810
phi_t[11]    0.526   0.005 0.227    0.193    0.333    0.493    0.705    0.968
p_t[1]       0.228   0.001 0.087    0.088    0.163    0.219    0.280    0.427
p_t[2]       0.551   0.003 0.127    0.312    0.459    0.552    0.642    0.794
p_t[3]       0.360   0.002 0.113    0.170    0.276    0.351    0.433    0.602
p_t[4]       0.506   0.002 0.119    0.285    0.421    0.505    0.589    0.742
p_t[5]       0.660   0.002 0.125    0.408    0.571    0.665    0.753    0.884
p_t[6]       0.571   0.002 0.118    0.344    0.489    0.570    0.657    0.797
p_t[7]       0.552   0.002 0.107    0.351    0.474    0.546    0.625    0.773
p_t[8]       0.306   0.002 0.098    0.137    0.236    0.298    0.369    0.518
p_t[9]       0.568   0.002 0.104    0.368    0.494    0.569    0.641    0.768
p_t[10]      0.588   0.002 0.135    0.334    0.491    0.588    0.683    0.845
p_t[11]      0.514   0.005 0.227    0.193    0.326    0.471    0.692    0.967
lp__      -467.799   0.095 3.558 -475.554 -470.011 -467.415 -465.191 -461.919
          n_eff  Rhat
phi_t[1]   4000 1.001
phi_t[2]   1905 1.003
phi_t[3]   1872 1.000
phi_t[4]   2596 1.000
phi_t[5]   2327 1.001
phi_t[6]   3044 1.000
phi_t[7]   2475 1.002
phi_t[8]   2401 1.001
phi_t[9]   2149 1.000
phi_t[10]  2262 1.000
phi_t[11]  2175 1.000
p_t[1]     3444 1.000
p_t[2]     2424 1.002
p_t[3]     2968 1.000
p_t[4]     3189 1.000
p_t[5]     2641 1.001
p_t[6]     4000 1.000
p_t[7]     2539 1.002
p_t[8]     3546 0.999
p_t[9]     2860 1.000
p_t[10]    2925 1.000
p_t[11]    2300 1.000
lp__       1409 1.001

Samples were drawn using NUTS(diag_e) at Wed Dec 16 23:20:55 2015.
For each parameter, n_eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor on split chains (at 
convergence, Rhat=1).
> 
> proc.time()
   user  system elapsed 
 21.538   0.739  45.525 
