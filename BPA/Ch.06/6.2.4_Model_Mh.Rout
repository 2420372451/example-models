
R version 3.2.3 (2015-12-10) -- "Wooden Christmas-Tree"
Copyright (C) 2015 The R Foundation for Statistical Computing
Platform: x86_64-apple-darwin13.4.0 (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

[Previously saved workspace restored]

> ## 6. Estimation of the size of a closed population
> ## 6.2. Generation and analysis of simulated data with data
> ## augmentation
> ## 6.2.4. Individual (random) effects: the heterogeneity model Mh
> 
> library(rstan)
Loading required package: ggplot2
rstan (Version 2.8.1, packaged: 2015-11-18 17:18:35 UTC, GitRev: 05c3d0058b6a)
For execution on a local, multicore CPU with excess RAM we recommend calling
rstan_options(auto_write = TRUE)
options(mc.cores = parallel::detectCores())
> rstan_options(auto_write = TRUE)
> options(mc.cores = parallel::detectCores())
> set.seed(1234)
> 
> ## Read data
> ## The data generation code is in bpa-code.txt, available at
> ## http://www.vogelwarte.ch/de/projekte/publikationen/bpa/complete-code-and-data-files-of-the-book.html
> stan_data <- read_rdump("Mh.data.R")
> 
> ## Initial values
> inits <- function() list(mean_p = 0.5, sigma = runif(1, 0.5, 0.9))
> 
> ## Parameters monitored
> params <- c("N", "mean_p", "sigma", "omega")
> 
> ## MCMC settings
> ni <- 15000
> nt <- 5
> nb <- 10000
> nc <- 4
> 
> ## Call Stan from R
> out <- stan("Mh.stan",
+             data = stan_data, init = inits, pars = params,
+             chains = nc, iter = ni, warmup = nb, thin = nt,
+             seed = 1,
+             open_progress = FALSE)
starting worker pid=7494 on localhost:11717 at 21:58:21.501
starting worker pid=7502 on localhost:11717 at 21:58:21.639
starting worker pid=7510 on localhost:11717 at 21:58:21.764
starting worker pid=7518 on localhost:11717 at 21:58:21.898

SAMPLING FOR MODEL 'Mh' NOW (CHAIN 1).

Chain 1, Iteration:     1 / 15000 [  0%]  (Warmup)
SAMPLING FOR MODEL 'Mh' NOW (CHAIN 2).

Chain 2, Iteration:     1 / 15000 [  0%]  (Warmup)
SAMPLING FOR MODEL 'Mh' NOW (CHAIN 3).

Chain 3, Iteration:     1 / 15000 [  0%]  (Warmup)
SAMPLING FOR MODEL 'Mh' NOW (CHAIN 4).

Chain 4, Iteration:     1 / 15000 [  0%]  (Warmup)
Chain 2, Iteration:  1500 / 15000 [ 10%]  (Warmup)
Chain 1, Iteration:  1500 / 15000 [ 10%]  (Warmup)
Chain 4, Iteration:  1500 / 15000 [ 10%]  (Warmup)
Chain 3, Iteration:  1500 / 15000 [ 10%]  (Warmup)
Chain 3, Iteration:  3000 / 15000 [ 20%]  (Warmup)
Chain 2, Iteration:  3000 / 15000 [ 20%]  (Warmup)
Chain 1, Iteration:  3000 / 15000 [ 20%]  (Warmup)
Chain 4, Iteration:  3000 / 15000 [ 20%]  (Warmup)
Chain 3, Iteration:  4500 / 15000 [ 30%]  (Warmup)
Chain 2, Iteration:  4500 / 15000 [ 30%]  (Warmup)
Chain 1, Iteration:  4500 / 15000 [ 30%]  (Warmup)
Chain 4, Iteration:  4500 / 15000 [ 30%]  (Warmup)
Chain 3, Iteration:  6000 / 15000 [ 40%]  (Warmup)
Chain 2, Iteration:  6000 / 15000 [ 40%]  (Warmup)
Chain 1, Iteration:  6000 / 15000 [ 40%]  (Warmup)
Chain 4, Iteration:  6000 / 15000 [ 40%]  (Warmup)
Chain 3, Iteration:  7500 / 15000 [ 50%]  (Warmup)
Chain 2, Iteration:  7500 / 15000 [ 50%]  (Warmup)
Chain 1, Iteration:  7500 / 15000 [ 50%]  (Warmup)
Chain 4, Iteration:  7500 / 15000 [ 50%]  (Warmup)
Chain 3, Iteration:  9000 / 15000 [ 60%]  (Warmup)
Chain 2, Iteration:  9000 / 15000 [ 60%]  (Warmup)
Chain 1, Iteration:  9000 / 15000 [ 60%]  (Warmup)
Chain 4, Iteration:  9000 / 15000 [ 60%]  (Warmup)
Chain 1, Iteration: 10001 / 15000 [ 66%]  (Sampling)
Chain 3, Iteration: 10001 / 15000 [ 66%]  (Sampling)
Chain 2, Iteration: 10001 / 15000 [ 66%]  (Sampling)
Chain 4, Iteration: 10001 / 15000 [ 66%]  (Sampling)
Chain 3, Iteration: 11500 / 15000 [ 76%]  (Sampling)
Chain 1, Iteration: 11500 / 15000 [ 76%]  (Sampling)
Chain 4, Iteration: 11500 / 15000 [ 76%]  (Sampling)
Chain 2, Iteration: 11500 / 15000 [ 76%]  (Sampling)
Chain 3, Iteration: 13000 / 15000 [ 86%]  (Sampling)
Chain 4, Iteration: 13000 / 15000 [ 86%]  (Sampling)
Chain 1, Iteration: 13000 / 15000 [ 86%]  (Sampling)
Chain 2, Iteration: 13000 / 15000 [ 86%]  (Sampling)
Chain 3, Iteration: 14500 / 15000 [ 96%]  (Sampling)
Chain 4, Iteration: 14500 / 15000 [ 96%]  (Sampling)
Chain 3, Iteration: 15000 / 15000 [100%]  (Sampling)
#  Elapsed Time: 166.299 seconds (Warm-up)
#                72.5858 seconds (Sampling)
#                238.884 seconds (Total)


Chain 1, Iteration: 14500 / 15000 [ 96%]  (Sampling)
Chain 4, Iteration: 15000 / 15000 [100%]  (Sampling)
#  Elapsed Time: 167.055 seconds (Warm-up)
#                77.6696 seconds (Sampling)
#                244.724 seconds (Total)


Chain 2, Iteration: 14500 / 15000 [ 96%]  (Sampling)
Chain 1, Iteration: 15000 / 15000 [100%]  (Sampling)
#  Elapsed Time: 167.036 seconds (Warm-up)
#                86.6089 seconds (Sampling)
#                253.644 seconds (Total)


Chain 2, Iteration: 15000 / 15000 [100%]  (Sampling)
#  Elapsed Time: 167.292 seconds (Warm-up)
#                94.1194 seconds (Sampling)
#                261.412 seconds (Total)

> ## Note: There may be divergent transitions after warmup.
> 
> ## Summarize posteriors
> print(out, digits = 3)
Inference for Stan model: Mh.
4 chains, each with iter=15000; warmup=10000; thin=5; 
post-warmup draws per chain=1000, total post-warmup draws=4000.

          mean se_mean     sd   2.5%     25%     50%     75%   97.5% n_eff
N      135.555   2.460 33.218 99.000 113.000 127.000 148.000 225.000   182
mean_p   0.234   0.007  0.089  0.056   0.171   0.239   0.300   0.389   177
sigma    1.528   0.034  0.428  0.838   1.212   1.483   1.793   2.480   162
omega    0.354   0.006  0.091  0.242   0.295   0.334   0.389   0.589   202
lp__   167.381   7.549 95.292 -7.947  99.440 163.991 232.573 362.111   159
        Rhat
N      1.011
mean_p 1.012
sigma  1.012
omega  1.009
lp__   1.011

Samples were drawn using NUTS(diag_e) at Wed Dec 16 22:03:01 2015.
For each parameter, n_eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor on split chains (at 
convergence, Rhat=1).
> 
> proc.time()
   user  system elapsed 
 20.434   0.692 301.039 
