---
title: <small><i>Stan Case Studies</i> (#1)</small><br /> On-Base Percentage over
  Time</b>
author: "<b>Bob Carpenter & Daniel Lee</b>"
date: "November 9, 2015"
output:
  html_document:
    fig_caption: yes
    fig_height: 4
    fig_width: 5
    keep_md: yes
    number_sections: no
  pdf_document: default
---

This Stan case study evaluates historical on-base data from [Major Leage Baseball](href="http://mlb.mlb.com/home), the top professional baseball league in the United States and Canada.

### What is OBP?

A commonly reported baseball statistic for batters is on-base percentage (OBP), which is defined as the percentage of plate appearances (PA) in which a batter reaches base safely due to a walk, a hit (single, double, triple, or home run), or being hit by the pitch. According to the Wikipedia's [page on OBP](https://en.wikipedia.org/wiki/On-base_percentage), among batters with 3000 or more plate apperances, Ted Williams has the highest career OBP with .482, whereas Bill Bergen has the lowest with .194.  (We follow baseball convention in reporting percentages as ratios with three digits of accuracy and no leading 0.)


## The Data

The data consists of boolean on-base outcomes (on-base: 1, not on-base: 0), defined as above, with an identifier for the year, pitcher, and batter.  For instance, the table might start with two plate appearances in 2015 by the same pitcher against two different batters in which the second plate appearances ends with the batter on base.

year|batter|pitcher|on_base
----|------|-------|-------
2015|193284|4374882|0
2015|194811|4374882|1
... | ...  |  ...  |...


 The data was downloaded in zip format from [Retrosheet.org](http://http://www.retrosheet.org) and the [event table format](http://www.retrosheet.org/datause.txt) converted to a simple CSV file with the four columns shown above.
 
## The Model

The simplest model we propose assumes batters and pitchers have abilities which do not change over their careers.  That is, each batter will have an ability $\alpha$, each pitcher an ability $\beta$, and there will be an intercept $\mu$ and a logistic regression determining the binary outcome as 
\[
y_n \sim \mbox{BernoulliLogit}(\mu + \alpha_{ii[n]} - \beta_{jj[n]})
\]
for $n \in 1{:}N$, where $ii[n] \in 1{:}I$ is the batter identifier and $jj[n] \in 1{:}J$ is the pitcher identifier.

In order for the model to be identifiable, we need to impose a fixed prior on both $\alpha$ and $\beta$.  For interpretability, it is easiest to given them both zero-mean priors.  To partially pool data across players and estimate how much to pool at the same time, we adopt a hierarchical model for batting ability
\[
\alpha_i \sim \mbox{Normal}(0, \sigma_{\alpha})
\]
for $i \in 1{:}I$, and a separate hierarchical model for pitching ability,
\[
\beta_j \sim \mbox{Normal}(0, \sigma_{\beta})
\] 
for $j \in 1{:}J$.  Given the low range of variability, we place a weakly informative half-Cauchy priors on the scale parameters,
\[
\sigma_{\alpha}, \sigma_{\beta} \sim \mbox{Cauchy}(0, 1),
\]
for $\sigma_{\alpha} > 0$ and $\sigma_{\beta} > 0$.  If the scales are near zero, there will be total pooling and as they grow, there is less pooling.  Given the limited range of player career abilities, these are not going to have large values.

Given that the batting and pitching abilities are given zero mean priors for interpretability and identifiability,  $\mbox{logit}^{-1}(\mu)$ is roughly in the range of 0.200 to 0.500, so $\mu$ will be in the range of -1.5 to 0, and therefore we can employ the weakly informative prior
\[
\mu \sim \mbox{Normal}(-0.75, 1.5).
\]

## Stan Code
```{r}
prog1 <- 
"
data {
  int<lower=0> I;                                  // number of batters
  int<lower=0> J;                                  // number of pitchers
  int<lower=0> N;                                  // number of at-bats
  int<lower=1, upper=I> ii[N];                     // batter for at-bat n
  int<lower=1, upper=J> jj[N];                     // pitcher for at-bat n
  int<lower=0, upper=1> y[N];                      // 1 for on-base at-bat n
}
parameters {
  real mu;                                         // intercept
  vector[I] alpha;                                 // batter ability
  vector[J] beta;                                  // pitcher ability
  real<lower=0> sigma_alpha;                       // batter ability scale
  real<lower=0> sigma_beta;                        // pitcher ability scale
}
model {
  sigma_alpha ~ cauchy(0, 1);                       // batting ability scale hyperprior
  sigma_beta ~ cauchy(0, 1);                        // pitching ability scale hyperprior
  alpha ~ normal(0, sigma_alpha);                   // batting ability hierarchical prior
  beta ~ normal(0, sigma_beta);                     // pitching ability hierarchical prior
  mu ~ normal(0, 2);                                // intercept prior
  for (n in 1:N)
    y[n] ~ bernoulli_logit(mu + alpha[ii[n]] - beta[jj[n]]);  // likelihood
} 
"
```

We can answer questions such as what Ted Williams's OBP would be expected to be if he played today instead of 50+ years ago (assuming he received no benefit from modern training);  more specifically, we might ask what his ability would be if he faced exactly the same opposing pitchers as Miguel Cabrera, Joe Morgan, or Ty Cobb.

## Fitting Simulated Data

As soon as we have an idea of the model we want to fit, we simulate data according to that model then make sure that we can recover the simulated parameters.

```{r}
inv_logit <- function(u) { 1 / (1 + exp(-u)); }
logit <- function(v) { log(v / (1 - v)); }

I <- 100;
J <- 200;

alpha <- rnorm(I, 0, 0.2);
beta <- rnorm(J, 0, 0.3);
mu <- -0.4;

N <- 50000;
y <- rep(NA, N);
ii <- sample(I, N, replace=TRUE);
jj <- sample(J, N, replace=TRUE);
y <- rbinom(N, 1, inv_logit(mu + alpha[ii] - beta[jj]));
```

```{r}
library(rstan);
fit <- stan(model_code=prog1, data=c("I", "J", "N", "ii", "jj", "y"));
print(fit);
```